{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import sys\n",
    "import random,progressbar, operator\n",
    "import hashlib, zlib, progressbar\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stream(n, k):\n",
    "    freqs = [1] * (n - k)\n",
    "    freqs += [1000] * k\n",
    "    random.shuffle(freqs)\n",
    "    stream = []\n",
    "    for i in range(n):\n",
    "        stream.append(random.choice(freqs))\n",
    "    return stream\n",
    "\n",
    "def generate_stream2(n, k):\n",
    "    return ['0'] * (n // 2) + [str(i % (k - 1) + 1) for i in range(n // 2)]\n",
    "\n",
    "def get_zero():\n",
    "    return 0\n",
    "def get_exact_count(inputlist):\n",
    "    res = defaultdict(get_zero)\n",
    "    for i in inputlist:\n",
    "        res[i] += 1\n",
    "    return res\n",
    "\n",
    "def get_list_from_file(fdir):\n",
    "    file1 = open(fdir, 'r')\n",
    "    Lines = file1.read().splitlines()\n",
    "    return Lines\n",
    "\n",
    "def get_exact_count(inputlist):\n",
    "    res = defaultdict(get_zero)\n",
    "    for i in inputlist:\n",
    "        res[i] += 1\n",
    "    return res\n",
    "\n",
    "def get_top_hitters(x, table = [], inputlist = []):\n",
    "    exact_count = get_exact_count(inputlist) if table == [] else table\n",
    "    sorted_table = dict(sorted(exact_count.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    res = []\n",
    "    cnt = 0\n",
    "    for key in sorted_table:\n",
    "        res.append(key)\n",
    "        cnt += 1\n",
    "        if(cnt == x):\n",
    "            break\n",
    "    return res\n",
    "\n",
    "def get_correct_rate(actual, mg, round_digits):\n",
    "    correct = 0\n",
    "    for i in mg:\n",
    "        if(i in actual):\n",
    "            correct += 1\n",
    "    return round(correct/len(mg),round_digits)\n",
    "\n",
    "def extract_words(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split()\n",
    "        for word in sentence_words:\n",
    "            words.append(word.lower())\n",
    "    unique_words = set(words)\n",
    "\n",
    "    return words, unique_words, len(unique_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Lossy Counting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossyCountingSketch(object):\n",
    "    def __init__(self, epsilon):\n",
    "        self.n = 0\n",
    "        self.count = defaultdict(int)\n",
    "        self.bucket_id = {}\n",
    "        self.epsilon = epsilon\n",
    "        self.current_bucket_id = 1\n",
    "\n",
    "    def get_count(self, item):\n",
    "        return self.count[item]\n",
    "    \n",
    "    def get_counts(self):\n",
    "        return self.count\n",
    "\n",
    "    def get_bucket_id(self, item):\n",
    "        return self.bucket_id[item]\n",
    "\n",
    "    def add(self, item):\n",
    "        self.n += 1\n",
    "        if item not in self.count:\n",
    "            self.bucket_id[item] = self.current_bucket_id - 1\n",
    "        self.count[item] += 1\n",
    "\n",
    "        if self.n % math.floor(1 / self.epsilon) == 0:\n",
    "            self.trim()\n",
    "            self.current_bucket_id += 1\n",
    "\n",
    "    def output_with_threshold_rate(self, threshold_rate):\n",
    "        return self.output(threshold_rate * self.n)\n",
    "\n",
    "    def trim(self):\n",
    "        for item in list(self.count.keys()):\n",
    "            if self.count[item] <= self.current_bucket_id - self.bucket_id[item]:\n",
    "                del self.count[item]\n",
    "                del self.bucket_id[item]\n",
    "\n",
    "    def output(self, threshold_count):\n",
    "        assert threshold_count > self.epsilon * self.n, \"too small threshold\"\n",
    "\n",
    "        self.trim()\n",
    "        for item, total in self.count.items():\n",
    "            if total >= threshold_count - self.epsilon * self.n:\n",
    "                yield item"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shakespeare Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Shakespeare_data.csv\")\n",
    "lines = df[\"PlayerLine\"]\n",
    "\n",
    "words, uniWords, numUniWords = extract_words(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"realData.txt\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "flist = get_list_from_file(\"realData.txt\")\n",
    "\n",
    "exact_count = get_exact_count(flist)\n",
    "actual_topx = get_top_hitters(25, [], flist)\n",
    "actual_topx.sort()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tcc_ceds_music.csv\")\n",
    "lines = df[\"lyrics\"]\n",
    "\n",
    "words, uniWords, numUniWords = extract_words(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Limitation and 3 datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = get_list_from_file(\"realData.txt\")\n",
    "exact_count = get_exact_count(flist)\n",
    "actual_topx = get_top_hitters(25, [], flist)\n",
    "actual_topx.sort()\n",
    "stream = flist\n",
    "n = 79989\n",
    "\n",
    "stream = words\n",
    "result = []\n",
    "with open(\"50.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        result.append(int(line.rstrip()))\n",
    "\n",
    "print(result)\n",
    "    \n",
    "percent = []\n",
    "print(\"running experiments...\")\n",
    "for ele in result:\n",
    "    epsilon = 1/ele\n",
    "    threshold = math.ceil(epsilon*n)\n",
    "    lcs = LossyCountingSketch(epsilon=epsilon)\n",
    "    for elem in stream:\n",
    "        lcs.add(elem)\n",
    "\n",
    "    lsct = []\n",
    "    for item in sorted(lcs.output(threshold),\n",
    "                            key=lambda x: x[1], reverse=True):\n",
    "        lsct.append(item)\n",
    "\n",
    "    if(len(lsct) >= 25):\n",
    "        lcs_correct = len(set(lsct[:25]).intersection(set(actual_topx)))\n",
    "    else:\n",
    "        lcs_correct = len(set(lsct).intersection(set(actual_topx[:len(lsct)])))\n",
    "\n",
    "    percent.append(lcs_correct/len(actual_topx))\n",
    "\n",
    "print(percent)\n",
    "\n",
    "with open(\"lca_result.txt\",\"w\") as f:\n",
    "    for item in percent:\n",
    "        f.write(str(item)+\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shakespeare and Lyrics (commented code is for Shakespeare dataset)  \n",
    "#### Please comment out the current dataset and uncomment the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51693\n",
      "2071963\n",
      "[50, 75, 100, 150, 200, 400, 600, 700, 750, 800, 850, 900, 950, 1000, 1050, 1200, 1300, 1400, 1500, 1700, 1750, 1800, 1850, 1900, 2000, 2500, 3000, 4000, 4350, 4400]\n",
      "running experiments...\n",
      "[0.08, 0.16, 0.24, 0.36, 0.32, 0.08, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"Shakespeare_data.csv\")\n",
    "# lines = df[\"PlayerLine\"]\n",
    "\n",
    "df = pd.read_csv(\"tcc_ceds_music.csv\")\n",
    "lines = df[\"lyrics\"]\n",
    "\n",
    "words, uniWords, numUniWords = extract_words(lines)\n",
    "\n",
    "print(numUniWords)\n",
    "print(len(words))\n",
    "\n",
    "result = []\n",
    "with open(\"50.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        result.append(int(line.rstrip()))\n",
    "\n",
    "print(result)\n",
    "\n",
    "stream = words\n",
    "\n",
    "# n = 814671\n",
    "n = 2071963\n",
    "actual_topx = get_top_hitters(25, [], words)\n",
    "\n",
    "percent = []\n",
    "print(\"running experiments...\")\n",
    "for ele in result:\n",
    "    epsilon = 1/ele\n",
    "    threshold = math.ceil(epsilon*n)\n",
    "    lcs = LossyCountingSketch(epsilon=epsilon)\n",
    "    for elem in stream:\n",
    "        lcs.add(elem)\n",
    "\n",
    "    lsct = []\n",
    "    for item in sorted(lcs.output(threshold),\n",
    "                            key=lambda x: x[1], reverse=True):\n",
    "        lsct.append(item)\n",
    "\n",
    "    if(len(lsct) >= 25):\n",
    "        lcs_correct = len(set(lsct[:25]).intersection(set(actual_topx)))\n",
    "    else:\n",
    "        lcs_correct = len(set(lsct).intersection(set(actual_topx[:len(lsct)])))\n",
    "\n",
    "    percent.append(lcs_correct/len(actual_topx))\n",
    "\n",
    "print(percent)\n",
    "\n",
    "with open(\"lca_result.txt\",\"w\") as f:\n",
    "    for item in percent:\n",
    "        f.write(str(item)+\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biased Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1, 10001):\n",
    "    if i <= 25:\n",
    "        numbers.extend([i] * 2)\n",
    "    else:\n",
    "        numbers.extend([i] * 1)\n",
    "\n",
    "print(len(numbers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1, 10001):\n",
    "    if i >= 9976:\n",
    "        numbers.extend([i] * 2)\n",
    "    else:\n",
    "        numbers.extend([i] * 1)\n",
    "\n",
    "print(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_count = get_exact_count(numbers)\n",
    "actual_topx = get_top_hitters(25, [], numbers)\n",
    "actual_topx.sort()\n",
    "\n",
    "stream = numbers\n",
    "epsilon = 0.001\n",
    "lcs = LossyCountingSketch(epsilon=epsilon)\n",
    "for elem in stream:\n",
    "    lcs.add(elem)\n",
    "\n",
    "lsct = []\n",
    "print(lcs.n*lcs.epsilon)\n",
    "\n",
    "threshold = math.ceil(lcs.n*lcs.epsilon)\n",
    "for item in sorted(lcs.output(threshold),\n",
    "                            key=lambda x: x[1], reverse=True):\n",
    "    lsct.append(item)\n",
    "\n",
    "print(\"n\",lcs.n)\n",
    "print(\"epsilon\",lcs.epsilon)\n",
    "\n",
    "print(\"Number of top hitters: \",len(lsct))\n",
    "\n",
    "lcs_correct = len(set(lsct[:25]).intersection(set(actual_topx)))\n",
    "\n",
    "print(\"\\n################## Count-Min Sketch SIMULATION REPORT ##################\\n\")\n",
    "print(\"Using Artificial Data\")\n",
    "print(\"\\n### PARAMETERS ###\")\n",
    "print(\"Width of bucket (K): \" + str(1/epsilon))\n",
    "print(\"Maximum Number of bucket:\",max(lcs._bucket_id.values()))\n",
    "print(\"Comparing Top \" + str(25) + \" heavy hitters.\")\n",
    "print(\"Space Used: \" + str(len(lcs._bucket_id.values())))\n",
    "print(\"\\n### RESULT ###\")\n",
    "if (False):\n",
    "    print(\"Actual top hitters: \")\n",
    "    print(actual_topx)\n",
    "    print(\"CMS top hitters: \")\n",
    "    print(lcs_correct)\n",
    "print(\"Number of actual top hitters: \" + str(len(actual_topx)))\n",
    "print(\"Number of LSC top hitters: \" + str(len(lsct[:25])))\n",
    "print(\"Percentage of corrected identified heavy hitters: \" + str(\n",
    "    lcs_correct/len(actual_topx))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCA paper: https://www.vldb.org/conf/2002/S10P03.pdf  \n",
    "Datasets:\n",
    "https://www.kaggle.com/datasets/kingburrito666/shakespeare-plays  \n",
    "https://www.kaggle.com/datasets/saurabhshahane/music-dataset-1950-to-2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
